# LoomNet
LoomNet is a multi-view diffusion model that generates spatially consistent images from a single input image. It builds a shared latent space by splatting and fusing view-specific features onto orthogonal planes. These fused planes are used to render 16 high-quality views in 15 seconds, outperforming prior methods.
